{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Brain Tumor Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:05.479973Z",
     "start_time": "2019-11-21T15:26:04.223284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# import the needed libs\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from os.path import isdir, isfile, join\n",
    "import copy\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from Utils.transforms import transforms\n",
    "\n",
    "from CNNs.unet import UNet\n",
    "#from Utils.loss import DiceLoss_wheighs\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#import Utils.view as vi\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "This code loads 2D images of health brains and bains containing tumors using a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:05.494921Z",
     "start_time": "2019-11-21T15:26:05.481917Z"
    }
   },
   "outputs": [],
   "source": [
    "class BrainSegmentationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, transform=None, subsampling_factor=2,\n",
    "                 in_channels = 3, out_channels = 1):\n",
    "        self.root = root\n",
    "        self.subsampling_factor = int(subsampling_factor)\n",
    "        self.data_path = []\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.transform = transform\n",
    "\n",
    "        def load_images(path):\n",
    "            images_dir = [join(path, f) for f in os.listdir(path) if join(path, f).endswith('_mask.tif')]\n",
    "            images_dir.sort()\n",
    "\n",
    "            return images_dir\n",
    "\n",
    "        self.data_path = load_images(self.root)\n",
    "#         print(self.data_path)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        mask = np.array(Image.open(self.data_path[index]))\n",
    "        mask = mask[::self.subsampling_factor,::self.subsampling_factor] \n",
    "        \n",
    "        img = np.array(Image.open(self.data_path[index].replace('_mask.tif', '.tif')))\n",
    "        img = np.transpose(img,(2,0,1))\n",
    "        img = img[:,::self.subsampling_factor,::self.subsampling_factor] \n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img, mask = self.transform((img, mask))\n",
    "        target = np.zeros(( self.out_channels,img.shape[2],img.shape[2]))\n",
    "        \n",
    "        \n",
    "        \n",
    "#         target[0] = mask==0\n",
    "#         target[1] = mask>0\n",
    "        target[0] = mask>0\n",
    "    \n",
    "        tensor_img = torch.FloatTensor(img)\n",
    "        tensor_target = torch.FloatTensor(target)\n",
    "      \n",
    "        return tensor_img, tensor_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.data_path)/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:06.579085Z",
     "start_time": "2019-11-21T15:26:05.497901Z"
    }
   },
   "outputs": [],
   "source": [
    "train_folder = '../Data/Traning_/train/'\n",
    "val_folder = '../Data/Traning_/val/'\n",
    "\n",
    "subsampling_factor=2\n",
    "crop_size=None\n",
    "\n",
    "# create datasets\n",
    "train_dataset = BrainSegmentationDataset(root=train_folder, out_channels = 1,\n",
    "                                         transform=transforms(angle=15, crop_size=crop_size, flip_prob=0.5,norm=(1,0.5)),\n",
    "                                        subsampling_factor=subsampling_factor)\n",
    "\n",
    "val_dataset = BrainSegmentationDataset(root=val_folder, out_channels = 1,\n",
    "                                       transform=transforms(crop_size=crop_size, norm=(1,0.5)),\n",
    "                                      subsampling_factor=subsampling_factor)\n",
    "\n",
    "# define the dataloader with the previous dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=60,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=60,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "loaders = {\"train\": train_loader, \"valid\": val_loader}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:06.589024Z",
     "start_time": "2019-11-21T15:26:06.581054Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Myloss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.size() == y_true.size()\n",
    "\n",
    "        return ???\n",
    "    \n",
    "\n",
    "def My_metric(predict, target, treshold=0.5):\n",
    "\n",
    "    \n",
    "    return ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a few images (one batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:08.082031Z",
     "start_time": "2019-11-21T15:26:06.591020Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0, 0, 0])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "print('Batch of training data')\n",
    "inputs, masks = next(iter(loaders['train']))\n",
    "# Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs + masks)\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out)\n",
    "\n",
    "\n",
    "print('Batch of validation data')\n",
    "inputs, masks = next(iter(loaders['valid']))\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:08.098985Z",
     "start_time": "2019-11-21T15:26:08.085024Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            if phase == 'train':\n",
    "                LOSS_train.append(epoch_loss)\n",
    "                ACC_train.append(epoch_acc)\n",
    "            if phase == 'val':\n",
    "                LOSS_val.append(epoch_loss)\n",
    "                ACC_val.append(epoch_acc)\n",
    "        \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:10.033810Z",
     "start_time": "2019-11-21T15:26:08.100981Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_ft_randstart = models.resnet18(pretrained=False)\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=1, init_features=32)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = Myloss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:10.038410Z",
     "start_time": "2019-11-21T15:26:10.034808Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:26:10.044783Z",
     "start_time": "2019-11-21T15:26:10.040792Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary(model, (3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-21T15:26:08.337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOSS_train = []\n",
    "LOSS_val = []\n",
    "ACC_train = []\n",
    "ACC_val = []\n",
    "\n",
    "model = train_model(model, loaders, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=150)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T15:25:44.350865Z",
     "start_time": "2019-11-21T15:25:44.202282Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOSSES = np.array([LOSS_train,LOSS_val]).T\n",
    "         \n",
    "plt.plot(LOSSES)\n",
    "plt.legend(['LOSS_train','LOSS_val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:35:19.032438Z",
     "start_time": "2019-11-21T14:35:05.288Z"
    }
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open('../Data/Testing/TCGA_HT_8106_19970727_13.tif')).T[:,::2,::2] \n",
    "\n",
    "mask = np.array(Image.open('../Data/Testing/TCGA_HT_8106_19970727_13_mask.tif')).T[::2,::2] \n",
    "\n",
    "\n",
    "norm=(1,0.5)\n",
    "\n",
    "img = img - (img.max() - img.min())/2\n",
    "if img.max()>0:\n",
    "    img = (img/img.max())*norm[0]/2\n",
    "img = img+norm[1]\n",
    "\n",
    "if img.max()>0:\n",
    "    mask = mask/mask.max()\n",
    "\n",
    "target = np.zeros((1,128,128))\n",
    "target[0] = mask>0\n",
    "\n",
    "print('target.shape = ', target.shape)\n",
    "print('img.shape = ', img.shape)\n",
    "\n",
    "print('target.max() = ', target.max())\n",
    "print('img.max() = ', img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:35:19.037425Z",
     "start_time": "2019-11-21T14:35:05.296Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "img = torch.FloatTensor(img.reshape((1,3, 128, 128))).to(device)\n",
    "predicted = model(img).cpu().data.numpy()\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:35:19.038423Z",
     "start_time": "2019-11-21T14:35:05.298Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux = np.empty((3,2,128,128))\n",
    "aux[0] = predicted[0]\n",
    "aux[1] = target\n",
    "aux[2] = np.abs(predicted[0] - target)\n",
    "vi.volume_show(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:35:19.040418Z",
     "start_time": "2019-11-21T14:35:05.300Z"
    }
   },
   "outputs": [],
   "source": [
    "vi.volume_show(((predicts > 0.5)-masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:35:19.041417Z",
     "start_time": "2019-11-21T14:35:05.302Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_folder = '../Data/Testing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:35:19.042412Z",
     "start_time": "2019-11-21T14:35:05.304Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_path = [join(testing_folder, f) for f in os.listdir(testing_folder) if join(testing_folder, f).endswith('_mask.tif')]\n",
    "samples_num = len(test_data_path)\n",
    "\n",
    "norm=(1,0.5)\n",
    "\n",
    "predicts = np.zeros((samples_num, 1, 128, 128))\n",
    "masks = np.zeros((samples_num, 1, 128, 128))\n",
    "\n",
    "for index, data_path in enumerate(test_data_path):\n",
    "    mask = np.array(Image.open(data_path))\n",
    "    mask = mask[::subsampling_factor,::subsampling_factor] \n",
    "\n",
    "    img = np.array(Image.open(data_path.replace('_mask.tif', '.tif')))\n",
    "    img = np.transpose(img,(2,0,1))\n",
    "    img = img[:,::subsampling_factor,::subsampling_factor]\n",
    "    \n",
    "    img = img - (img.max() - img.min())/2\n",
    "    if img.max()>0:\n",
    "        img = (img/img.max())*norm[0]/2\n",
    "    img = img+norm[1]\n",
    "\n",
    "    if img.max()>0:\n",
    "        mask = mask/mask.max()\n",
    "\n",
    "    target = np.zeros((1,128,128))\n",
    "    target[0] = mask>0.5\n",
    "    \n",
    "    img = torch.FloatTensor(img.reshape((1,3, 128, 128))).to(device)\n",
    "    predicted = model(img).cpu().data.numpy()\n",
    "    \n",
    "    predicts[index] = predicted\n",
    "    masks[index,0] = target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:35:19.044407Z",
     "start_time": "2019-11-21T14:35:05.306Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vi.volume_show(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:35:19.045404Z",
     "start_time": "2019-11-21T14:35:05.308Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dices = DICE_metric(predicts>0.5, masks, treshold=0.5).squeeze()\n",
    "np.average(dices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
